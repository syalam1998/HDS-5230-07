{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac85444-4aed-48be-8cb4-0366e482daa8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "NAME:Yalam snigdha\n",
    "Assignment number:9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dfab5e-51c7-4f2f-aa6e-781085bb9cb3",
   "metadata": {},
   "source": [
    "## Question 1: Which model had the best generalizable performance?\n",
    "\n",
    "Based on the comparison of model performances, Logistic Regression model has the best generalizable performance with a test accuracy of **0.718**.\n",
    "\n",
    "| Model                  | Train Accuracy | Test Accuracy |\n",
    "|------------------------|----------------|---------------|\n",
    "| Logistic               | 0.7333         | **0.718**     |\n",
    "| Null                   | 0.6467         | 0.608         |\n",
    "| Logistic_L1_C_1        | 0.732          | 0.716         |\n",
    "| Logistic_L1_C_01       | 0.726          | 0.706         |\n",
    "| Logistic_L1_C_10       | 0.7347         | 0.718         |\n",
    "| Logistic_L1_C_auto     | 0.7233         | 0.708         |\n",
    "| Logistic_SL1_C_auto    | 0.7307         | 0.714         |\n",
    "| RandomForest_noCV      | 0.9993         | 0.686         |\n",
    "\n",
    "The Random Forest overfitted (train accuracy near 1.0), while regularized logistic models slightly underfit. The basic logistic model balanced both training and testing which is actually better compared to Random Forest because Random Forest is performing poorly under new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "421c997f-f34e-4304-b590-1f659272ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2: \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"PatientAnalyticFile.csv\")\n",
    "\n",
    "# Create binary classification target: 1 if patient died, else 0\n",
    "df[\"Died\"] = df[\"DateOfDeath\"].notnull().astype(int)\n",
    "\n",
    "# Use the same predictors the professor used\n",
    "predictors = [\n",
    "    'Gender', 'Race', 'Myocardial_infarction', 'Congestive_heart_failure',\n",
    "    'Peripheral_vascular_disease', 'Stroke', 'Dementia', 'Pulmonary',\n",
    "    'Obesity', 'Depression', 'Hypertension', 'Drugs', 'Alcohol'\n",
    "]\n",
    "\n",
    "# Filter dataset\n",
    "X = df[predictors]\n",
    "y = df[\"Died\"]\n",
    "\n",
    "# One-hot encode categorical features (Gender, Race)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into train and holdout (same across all models)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f962059f-22d4-4bb0-8efe-a9c501653d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Solver used  Training subset accuracy  Holdout subset accuracy  \\\n",
      "0   liblinear                    0.6517                   0.6518   \n",
      "1        saga                    0.6517                   0.6518   \n",
      "2       lbfgs                    0.6517                   0.6518   \n",
      "3   newton-cg                    0.6517                   0.6518   \n",
      "4         sag                    0.6517                   0.6518   \n",
      "\n",
      "   Time taken (s)  \n",
      "0          0.0132  \n",
      "1          0.1203  \n",
      "2          0.0132  \n",
      "3          0.0269  \n",
      "4          0.2414  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# List of solvers to test\n",
    "solvers = ['liblinear', 'saga', 'lbfgs', 'newton-cg', 'sag']\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each solver\n",
    "for solver in solvers:\n",
    "    try:\n",
    "        # Start timer to keep track of the time a solver took to predict\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Special handling for liblinear since it does NOT support penalty=None\n",
    "        if solver == 'liblinear':\n",
    "            model = LogisticRegression(penalty='l2', C=1e10, solver='liblinear', max_iter=1000)\n",
    "        else:\n",
    "            model = LogisticRegression(penalty=None, solver=solver, max_iter=1000)\n",
    "\n",
    "        # Fit model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Stop timer\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        # Predict and calculate accuracies\n",
    "        train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "        holdout_acc = accuracy_score(y_holdout, model.predict(X_holdout))\n",
    "\n",
    "        # Save result\n",
    "        results.append({\n",
    "            'Solver used': solver,\n",
    "            'Training subset accuracy': round(train_acc, 4),\n",
    "            'Holdout subset accuracy': round(holdout_acc, 4),\n",
    "            'Time taken (s)': round(elapsed_time, 4)\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        # If a solver fails, store the error\n",
    "        results.append({\n",
    "            'Solver used': solver,\n",
    "            'Training subset accuracy': 'Error',\n",
    "            'Holdout subset accuracy': 'Error',\n",
    "            'Time taken (s)': str(e)\n",
    "        })\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994e5d64-d9f9-40cf-b79b-f678c379c6e2",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "| Solver      | Training subset accuracy | Holdout subset accuracy | Time taken (s) |\n",
    "|-------------|--------------------------|-------------------------|---------------|\n",
    "| liblinear   | 0.6517                   | 0.6518                  | 0.0161        |\n",
    "| saga        | 0.6517                   | 0.6518                  | 0.1191        |\n",
    "| lbfgs       | 0.6517                   | 0.6518                  | 0.0359        |\n",
    "| newton-cg   | 0.6517                   | 0.6518                  | 0.0269        |\n",
    "| sag         | 0.6517                   | 0.6518                  | 0.2605        |\n",
    "\n",
    "\n",
    "\n",
    "I trained logistic regression models using five other solvers in Scikit-Learn (liblinear, saga, lbfgs, newton-cg, and sag) and tested their accuracy and compute time. The models were trained on the same 80% training set and tested on the same 20% holdout set. Regularization was successfully turned off (either by penalty=None or by setting C=1e10 for liblinear).\n",
    "All the solvers produced identical accuracy scores (65.17% on train and 65.18% on holdout), indicating the same generalization performance.\n",
    "However, liblinear recorded the minimum computation time (0.0161s) and was the most effective solver of this problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b660e34-bf5d-41f4-8375-79cacf7fc04f",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "Based on results above, the accuracy measures of all solvers (liblinear, saga, lbfgs, newton-cg, and sag) are the same:\n",
    "\n",
    "Training subset accuracy: 0.6517 for all solvers\n",
    "Holdout subset accuracy: 0.6518 for all solvers\n",
    "\n",
    "Since the accuracy measures are uniform for all solvers, the only differentiating factor is execution time. Rank based on minimum execution time:\n",
    "\n",
    "liblinear: 0.0161 seconds (best of all)\n",
    "newton-cg: 0.0269 seconds\n",
    "lbfgs: 0.0359 seconds\n",
    "saga: 0.1191 seconds\n",
    "sag: 0.2605 seconds (slowest of all)\n",
    "\n",
    "So, liblinear is best in terms of computational efficiency as it produces the same level of accuracy as all other solvers but in the least amount of running time. If efficiency is an issue in your program, liblinear would be the perfect solver for this particular problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3314ac-4495-46b2-8470-38fc76ddb798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
